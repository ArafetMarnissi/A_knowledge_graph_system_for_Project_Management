{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers pandas torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarization complete. Check 'summarized_df.csv' for results.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Load the pre-trained T5 model and tokenizer\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Function to summarize a paragraph using T5\n",
    "def summarize_paragraph(paragraph):\n",
    "    input_text = \"summarize: \" + paragraph\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    summary_ids = model.generate(inputs, max_length=150, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Load the dataframe from the CSV file\n",
    "df = pd.read_csv(\"df.csv\")\n",
    "\n",
    "# Summarize all paragraphs in the dataframe\n",
    "df['summarized_paragraphs'] = df['processed_paragraphs'].apply(summarize_paragraph)\n",
    "\n",
    "# Save the summarized dataframe to a new CSV file\n",
    "df.to_csv(\"summarized_df.csv\", index=False)\n",
    "\n",
    "print(\"Summarization complete. Check 'summarized_df.csv' for results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 175 entries, 0 to 174\n",
      "Data columns (total 8 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   Unnamed: 0             175 non-null    int64 \n",
      " 1   sections               175 non-null    object\n",
      " 2   paragraphs             175 non-null    object\n",
      " 3   bigram_dict            175 non-null    object\n",
      " 4   trigram_dict           175 non-null    object\n",
      " 5   sentences              175 non-null    object\n",
      " 6   processed_paragraphs   175 non-null    object\n",
      " 7   summarized_paragraphs  175 non-null    object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 11.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                processed_paragraphs  \\\n",
      "0   The purpose of the  Practice Standard for Pro...   \n",
      "1   The de nition of Project Risk Management, as ...   \n",
      "2   Project Risk Management is not an optional ac...   \n",
      "3   Project Risk Management is a valuable compone...   \n",
      "4   Figure 12. Critical Success Factors for Proje...   \n",
      "\n",
      "                               summarized_paragraphs  \n",
      "0  practice standard for Project Risk Management ...  \n",
      "1  project risk is an uncertain event or conditio...  \n",
      "2  Project Risk Management is not an optional act...  \n",
      "3  Project Risk Management should be conducted in...  \n",
      "4  Speci c criteria for success of each Project R...  \n"
     ]
    }
   ],
   "source": [
    "# Display the original and summarized paragraphs side by side\n",
    "comparison_df = df[['processed_paragraphs', 'summarized_paragraphs']]\n",
    "\n",
    "# Save the comparison to a new CSV file\n",
    "comparison_df.to_csv(\"comparison_df.csv\", index=False)\n",
    "\n",
    "# Print the first few comparisons for review\n",
    "print(comparison_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pmia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
